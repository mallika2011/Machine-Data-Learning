<!--     Summary of your Genetic Algorithm with all the steps, also mention if you have made any major changes to the base genetic algorithm.
    Three diagrams that showcase your first three iterations as shown in the attached image.
    Explain your fitness function.
    Explain your crossover function.
    How exactly did you apply the mutations(if any).
    What were your hyperparameters like pool size, splitting point for creating new genes, etc and why did you choose those parameters?
    Statistical information like Number of iterations to converge, etc.
    What heuristics did you apply, mention the ones that didn't work too.
     Trace of output for the first 10 steps as shown:

    Initial population
    Vectors selected for crossover
    Vectors after applying the crossover
    Vectors before and after mutation

    Anything else that you used, tricks, brute force, etc. that we should be aware of. -->



<!-- # how to choose individuals for crossover
# how to choose the next gen

#flow of the program
#main

#generate initial genration (mutation) size 100

#while loop
    #create a utility array that stores the error for every individual in the population
    #parenterrors[]
    #get the probability of selection for every parent for going into crossover, this will generate the probaliliites based on the error
    #above function will return an array: parentprobality

    #for i in range(number of time you want to do crossover):
    #   pick two parents using numpy.random.choice
    #   cross them over, now we have two new
    #   choose between them. how? -> top two? according to probability?
    #   for now, choose only the children ignore the parents
    #   mutate the crossovers
    #   put them into an array called nextgen[] -->


# GENETIC ALGORITHM 

**TEAM NO: 62**<br>
**Mallika Subramanian - 2018101041**<br>
**Tanvi Karandikar    - 2018101059**


## Summary of the genetic algorithm : 

The genetic algorithm is a search heuristic that is inspired by Charles Darwinâ€™s theory of natural evolution. This algorithm reflects the process of natural selection where the fittest individuals are selected for reproduction in order to produce offspring of the next generation.

**The stepwise explanation of our implementation is as follows :**

> *STEP 1: GENERATE INITIAL POPULATION*

To start the genetic algorithm, we require a population of some **pop_size** number of individuals. These individuals are generated by mutating the vector (overfit on the training dataset) that is provided to us. 
This produces the starting generation for the GA. 

We have ensured that the first generation of individuals is diverse by keeping the probability of mutation factor high, that is the probability with which a gene is mutated in  a chromosome is high. 
This is so that the algorithm does not converge to a local minima in the very beginning itself 
 <!--check this line please  -->

```python
# generate the population
for i in range(pop_size):
    temp = np.copy(vector_og)
    population[i] = np.copy(mutateall(temp,0.9,mutate_range))
```


> *STEP 2: OBTAIN ERRORS FOR THIS GENERATION*

Once the first generation is ready, we obtain the errors of all the individuals (parents for the next generation). This is done to determine the fitness of each individual and to decide their progress into the next generation.

```python
# generate errors for each individual in the population
for j in range(pop_size):
    # passing a list to the get_errors function
    temp = population[j].tolist()
    err = server.get_errors(key, temp)
    # adding the two errors and storing in parenterror - fitness function
    parenterrors[j] = np.copy((err[0]+err[1]))
    parenterrors1[j] = np.copy((err[0]))
    parenterrors2[j] = np.copy((err[1]))

```

> *STEP 3: CROSSOVER OF PARENT POULATION*

* Once the parent errors have been obtained, the parent population is sorted in the **increasing** order of their *errors* the crossover step takes place. 

* Crossovers happpen until **pop_size** children have been produced. The parens for crossover are chosen from a set of top **k** parents in the parent population. 

* The parents chosen from the previous step are sent to the crossover function which returns two children (two vectors).
The ```crossover``` function returns **mutated** the child vectors.
These 2 child vectors are then appended to the child population.

* If the child vector is identical to the parent vector, it is not included in the child population and that iteration is discarded.

```python
child_population = np.zeros((pop_size, MAX_DEG))
new_iter = 0

while(new_iter < pop_size):


    #Select randomly among top k parents  (For now k =10)
    arr = crossover_select2(parenterrors, cross_select_from)

    # Sending parents for crossover
    temp = crossover(population[arr[0]], population[arr[1]],mutate_range,prob_mut_cross)

    #case1 : child vector is identical to parent vector
    if temp[0].tolist() == population[arr[0]].tolist() or temp[1].tolist() == population[arr[0]].tolist() or temp[0].tolist() == population[arr[1]].tolist() or temp[1].tolist() == population[arr[1]].tolist():
        continue
    
    #case2 : append to child population
    child_population[new_iter] = np.copy(temp[0])
    new_iter += 1

    child_population[new_iter] = np.copy(temp[1])
    new_iter += 1
```

> *STEP 4: OBTAIN ERRORS FOR CHILD POPULATION*

The errors for the child population are obtained. The child population is then sorted in the increasing order of their errors (sum of the train and validation errors obtained).

```python
    childerrors = np.zeros(pop_size)
    childerrors1 = np.zeros(pop_size)
    childerrors2 = np.zeros(pop_size)

    # generate errors for each child
    for j in range(pop_size):
        temp = child_population[j].tolist()
        err = server.get_errors(key, temp)

        # adding the two errors and storing in parenterror
        childerrors[j] = np.copy((err[0]+err[1]))
        childerrors1[j] = np.copy((err[0]))
        childerrors2[j] = np.copy((err[1]))

    # Sort children
    childinds = np.copy(childerrors.argsort())
    childerrors = np.copy(childerrors[childinds[::1]])
    childerrors1 = np.copy(childerrors1[childinds[::1]])
    childerrors2 = np.copy(childerrors2[childinds[::1]])
    child_population = np.copy(child_population[childinds[::1]])
```

> *STEP 5: CREAT THE NEXT GENERATION*

* Now that we have the **pop_size** parents and **pop_size** children we have to prepare a population of **pop_size** indivduals by selection them from the parents and children. 

* The new generation will have top ```select_sure``` number of parents and children with cerainity. This is so that the best (best fitness and least error) chromosomes of both population are advanced to the next generation. This is stored in a ```tempbank```.

```python
# now the children are sorted and stored in child and parents are sorted in population
# we will now create a tempbank array to store top k parents, top k childs and rest being sorted taking from the top
tempbankerr = np.zeros(pop_size)
tempbankerr1 = np.zeros(pop_size)
tempbankerr2 = np.zeros(pop_size)
tempbank= np.zeros((pop_size, MAX_DEG))

for j in range(select_sure):
    
    #choosing the top jth parent and putting in the array
    tempbank[j]=np.copy(population[j])
    tempbankerr[j]=np.copy(parenterrors[j])
    tempbankerr1[j]=np.copy(parenterrors1[j])
    tempbankerr2[j]=np.copy(parenterrors2[j])
    
    #choosing the top jth child and putting it into the array 
    tempbank[j+select_sure]=np.copy(child_population[j])
    tempbankerr[j+select_sure]=np.copy(childerrors[j])
    tempbankerr1[j+select_sure]=np.copy(childerrors1[j])
    tempbankerr2[j+select_sure]=np.copy(childerrors2[j]) 
```

* The parent and children population is combined into a single ```candidates``` array and the remaining **```pop_size - select_sure```** number of individuals are selected.

```python
# combining parents and children into one array
candidates = np.copy(np.concatenate([population[select_sure:], child_population[select_sure:]]))
candidate_errors = np.copy(np.concatenate([parenterrors[select_sure:], childerrors[select_sure:]]))
candidate_errors1 = np.copy(np.concatenate([parenterrors1[select_sure:], childerrors1[select_sure:]]))
candidate_errors2 = np.copy(np.concatenate([parenterrors2[select_sure:], childerrors2[select_sure:]]))

# sorting all the candidates by error
candidate_errors_inds = candidate_errors.argsort()
candidate_errors = np.copy(candidate_errors[candidate_errors_inds[::1]])
candidate_errors1 = np.copy(candidate_errors1[candidate_errors_inds[::1]])
candidate_errors2 = np.copy(candidate_errors2[candidate_errors_inds[::1]])
candidates = np.copy(candidates[candidate_errors_inds[::1]])

# TODO: Select the best popsize - 2*(select_sure)
cand_iter = 0

while(cand_iter + 2*select_sure < pop_size):
    tempbank[cand_iter+2*select_sure] = np.copy(candidates[cand_iter])
    tempbankerr[cand_iter+2*select_sure] = np.copy(candidate_errors[cand_iter])
    tempbankerr1[cand_iter+2*select_sure] = np.copy(candidate_errors1[cand_iter])
    tempbankerr2[cand_iter+2*select_sure] = np.copy(candidate_errors2[cand_iter])
    cand_iter += 1
```

> *STEP 6: SETTING THE NEW POPULATION*

This is now set as the next generation of individuals for the GA. Their errors are computed and the population is sorted. 

```python
#now setting the next population
population=np.copy(tempbank)
parenterrors=np.copy(tempbankerr)
parenterrors1=np.copy(tempbankerr1)
parenterrors2=np.copy(tempbankerr2)

#we will now sort before updating min_error
parenerrorsinds = parenterrors.argsort()
parenterrors = np.copy(parenterrors[parenerrorsinds[::1]])
parenterrors1 = np.copy(parenterrors1[parenerrorsinds[::1]])
parenterrors2 = np.copy(parenterrors2[parenerrorsinds[::1]])
population = np.copy(population[parenerrorsinds[::1]])
```

> *STEP 7: CHECK MINIMUM*

If the error of the fittest individual is lesser than the current minimum error, the ```min_error``` and the ```to_send``` vector are updated. 

```python
if(min_error == -1 or min_error > parenterrors[0]):
            to_send = np.copy(population[0])
            min_error = np.copy(parenterrors[0])
            min_error1 = np.copy(parenterrors1[0])
            min_error2 = np.copy(parenterrors2[0])
            nochange=0
else:
    print("no improvement!!!")
```

> *STEP 8: REPEAT STEPS 3 TO 7*

The Genetic Algorithm is repeated (Step 3 - Step 7) for ```iter``` number of iterations (this was done considering the requests that can be made to the server in order to obtain the errors for the different vectors was limited).


